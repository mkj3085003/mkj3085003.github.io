<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Kaijing Ma | Homepage</title>
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 200 100'%3E%3Cdefs%3E%3ClinearGradient id='cyberGradient' x1='0%25' y1='0%25' x2='100%25' y2='0%25'%3E%3Cstop offset='0%25' style='stop-color:%236ea8ff;stop-opacity:1' /%3E%3Cstop offset='100%25' style='stop-color:%23a064ff;stop-opacity:1' /%3E%3C/linearGradient%3E%3C/defs%3E%3Cg fill='none' stroke='url(%23cyberGradient)' stroke-width='16' stroke-linecap='round' stroke-linejoin='round'%3E%3C!-- M (Ma) --%3E%3Cpath d='M15 80 V20 L45 55 L75 20 V80' /%3E%3C!-- - (Logic Link) --%3E%3Cpath d='M95 50 H110' stroke='%23ffffff' stroke-width='12' /%3E%3C!-- KJ (Kaijing) --%3E%3Cpath d='M130 20 V80 M130 50 L160 20 M130 50 L155 55 M175 20 V80 Q175 95 155 95' /%3E%3C/g%3E%3C/svg%3E">
    <link rel="stylesheet" href="style.css">
</head>
<script>
    function updateDynamicTimeline() {
        const startDate = new Date(2022, 0, 1); // 时间轴起点：2022年1月
        const endDate = new Date(2026, 0, 1);   // 时间轴终点：2026年1月
        const today = new Date();

        // 1. 计算总分钟数和已过去分钟数（比按月算更精确）
        const totalDuration = endDate - startDate;
        const elapsed = today - startDate;
        
        // 计算百分比位置
        let scrollPercent = (elapsed / totalDuration) * 100;
        if (scrollPercent > 100) scrollPercent = 100; // 封顶到2026年
        if (scrollPercent < 0) scrollPercent = 0;

        // 2. 更新 Today 线的位置
        const todayLine = document.getElementById('todayLine');
        const todayLabel = document.getElementById('todayLabel');
        if (todayLine) {
            todayLine.style.left = scrollPercent + '%';
            
            // 更新标签文字，例如 "Today (Dec 2025)"
            const monthNames = ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"];
            todayLabel.innerText = `Today (${monthNames[today.getMonth()]} ${today.getFullYear()})`;
        }

        // 3. 自动调整所有标记为 .auto-width 的进行中经历条
        const autoBars = document.querySelectorAll('.auto-width');
        autoBars.forEach(bar => {
            const startYear = parseInt(bar.getAttribute('data-start-year'));
            const startMonth = parseInt(bar.getAttribute('data-start-month')) - 1; // JS月份从0开始
            const barStartDate = new Date(startYear, startMonth, 1);
            
            const barStartElapsed = barStartDate - startDate;
            const barStartPercent = (barStartElapsed / totalDuration) * 100;
            
            // 设置起点和宽度
            bar.style.left = barStartPercent + '%';
            bar.style.width = (scrollPercent - barStartPercent) + '%';
        });
    }

    // 页面加载和时间变化时运行
    window.onload = updateDynamicTimeline;
</script>
<body>

<!-- ====================== PARTICLE BACKGROUND ======================= -->
<div class="particles">
    <!-- generate 25 floating particles -->
    <script>
        for (let i=0;i<25;i++){
            const p=document.createElement('div');
            p.className='particle';
            p.style.left=Math.random()*100+'%';
            p.style.top=Math.random()*100+'%';
            p.style.animationDelay=(Math.random()*10)+'s';
            p.style.opacity=Math.random();
            document.querySelector('.particles').appendChild(p);
        }
    </script>
</div>

<!-- ====================== NAVIGATION ======================= -->
<nav>
    <ul>
        <li><a href="index.html">Home</a></li>
        <a href="CV.pdf" target="_blank">CV</a>
    </ul>
</nav>

<div class="container">


<!-- ====================== WELCOME ======================= -->
<div class="welcome" style="margin-top: -20px;">
    <div class="profile-box" style="margin-top: 120px;">
        <img src="assets/kaijing.jpg" alt="Profile Photo">

        <div class="social-links">

            <a href="https://github.com/mkj3085003">
                <svg class="icon" viewBox="0 0 24 24">
                    <path d="M12 2C6.48 2 2 6.58 2 12.25c0 4.5 2.87 8.32 6.84 9.68.5.1.68-.22.68-.48v-1.7c-2.78.63-3.37-1.37-3.37-1.37-.46-1.2-1.14-1.52-1.14-1.52-.93-.66.07-.64.07-.64 1.03.07 1.57 1.1 1.57 1.1.91 1.6 2.38 1.14 2.96.88.09-.68.35-1.14.63-1.4-2.22-.26-4.56-1.14-4.56-5.1 0-1.14.39-2.07 1.03-2.8-.1-.26-.45-1.33.1-2.74 0 0 .84-.27 2.75 1.07A9.18 9.18 0 0 1 12 7.5c.85 0 1.7.12 2.5.34 1.9-1.34 2.75-1.07 2.75-1.07.55 1.41.2 2.48.1 2.74.64.73 1.03 1.66 1.03 2.8 0 3.98-2.35 4.83-4.6 5.08.36.32.68.94.68 1.92v2.84c0 .27.18.6.69.48A10.27 10.27 0 0 0 22 12.25C22 6.58 17.52 2 12 2Z"/>
                </svg>
                GitHub
            </a>

            <a href="mailto:2151400@tongji.edu.cn">
                <svg class="icon" viewBox="0 0 24 24">
                    <path d="M4 4h16c1.1 0 2 .9 2 2v1l-10 6L2 7V6c0-1.1.9-2 2-2Zm18 5-10 6L2 9v9c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V9Z"/>
                </svg>
                Email
            </a>

            <a href="https://scholar.google.com/citations?hl=zh-CN&user=0nt08kUAAAAJ">
                <svg class="icon" viewBox="0 0 24 24">
                    <path d="M12 3 2 9l10 6 10-6-10-6Zm0 8.7L4.6 9 12 5.3 19.4 9 12 11.7Z" />
                    <path d="M6 12.5v4.5L12 22l6-5v-4.5l-6 3.5-6-3.5Z"/>
                </svg>
                Google Scholar
            </a>

        </div>

    </div>

    <div class="intro-text">
        <h1>Hello! I'm <span class="highlight">Kaijing Ma</span></h1>

        <h3>About Me</h3>
        <p>
            I recently graduated from <b><span class="highlight">Tongji University</span></b> with a Bachelor's degree in <span class="highlight">Computer Science and Technology</span>. 
            My name carries the meaning of <i>lush growth and thriving energy</i>, and I am naturally <span class="highlight">cheerful</span>, <span class="highlight">optimistic</span>, and <span class="highlight">curious</span>. 
            I love exploring diverse facets of life — from arts and literature to hands-on experiments, tinkering with robots, and building quirky projects for fun. 
            I am always eager to embrace new challenges and learn through both collaborative teamwork and self-driven exploration.
        </p>


        <h3>Research Interests</h3>
        <p>My research vision focuses on transforming the abstract concept of  <b><span class="highlight">"intelligence"</span></b> into engineering systems that are <span class="highlight">constructible</span>, <span class="highlight">measurable</span>, and <span class="highlight">explainable</span>. 
        Specifically, my research interests include:</p>
        <ul>
            <li><b class="highlight">Natural Language Processing (NLP)</b> — studying language understanding and generation with large-scale models.</li>
            <li><b class="highlight">Reasoning Capabilities of LLMs</b> — evaluating, enhancing, and systematically improving how LLMs perform logical and multi-step reasoning.</li>
            <li><b class="highlight">Mechanistic Interpretability</b> — uncovering the underlying mechanisms behind LLM reasoning processes.</li>
            <li><b class="highlight">AI Safety</b> — designing methods to ensure robust, safe, and aligned AI behavior.</li>
            <li><b class="highlight">Embodied Intelligence</b> — exploring how AI can interact with and learn from physical environments and robotics systems.</li>
        </ul>
    </div>

</div>

<!-- ====================== EDUCATION ======================= -->
<h2>Education</h2>

<div class="info-block">
    <div class="info-title">Tongji University
        <a href="https://www.tongji.edu.cn/eng/index.htm" target="_blank" class="pub-btn" style="margin-left:10px" >Link</a>
    </div>
    <div class="info-sub">B.S. in Computer Science · 2021–2025</div>
</div>

<!-- ====================== PERSONAL DEVELOPMENT TIMELINE ======================= -->
<section class="cyber-timeline-section">
    <h2>Personal Development Timeline</h2>

    <!-- 顶部进度指示器 -->
    <div class="scroll-progress-container">
        <div class="scroll-progress-bar" id="timelineProgress"></div>
    </div>

    <!-- 滚动查看器 -->
    <div class="timeline-scroll-viewer" id="timelineViewer">
        <div class="timeline-canvas">
            
            <!-- 今天标记线 (由 JS 自动定位) -->
            <div class="today-line" id="todayLine">
                <span class="today-label" id="todayLabel">Today</span>
            </div>

            <!-- 背景年份刻度 -->
            <div class="year-markers">
                <div class="year-mark"><span>2022</span></div>
                <div class="year-mark"><span>2023</span></div>
                <div class="year-mark"><span>2024</span></div>
                <div class="year-mark"><span>2025</span></div>
                <div class="year-mark"><span>2026</span></div>
            </div>

            <!-- 经历轨道 -->
            <div class="experience-tracks">
                
                <!-- Track 1: 长期的学术积累 -->
                <div class="track-row">
                    <!-- MAP: 2023.10 开始，持续至今 -->
                    <div class="exp-bar ongoing auto-width" data-start-year="2023" data-start-month="10">
                        <div class="bar-content">
                            <span class="bar-title">MAP Open Source Community</span>
                            <span class="bar-tag">Reasoning Benchmarks (KOR-Bench, SuperGPQA)</span>
                        </div>
                    </div>
                </div>

                <!-- Track 2: 视觉、交叉与前沿 -->
                <div class="track-row">
                    <!-- SRIAS: 2022.06 - 2023.09 (静态宽度) -->
                    <div class="exp-bar" style="left: 10.4%; width: 31.3%;">
                        <div class="bar-content">
                            <span class="bar-title">SRIAS (Tongji)</span>
                            <span class="bar-tag">Pedestrian Re-ID & Cloud-Edge Algorithms</span>
                        </div>
                    </div>
                    <!-- SPAR: 2024.02 - 2024.06 -->
                    <div class="exp-bar" style="left: 52%; width: 8.3%;">
                        <div class="bar-content">
                            <span class="bar-title">SPAR Project</span>
                            <span class="bar-tag">AI Safety & Steganography</span>
                        </div>
                    </div>
                    <!-- MIT: 2025.06 开始，持续至今 -->
                    <div class="exp-bar ongoing auto-width" data-start-year="2025" data-start-month="6">
                        <div class="bar-content">
                            <span class="bar-title">MIT CSAIL (Remote)</span>
                            <span class="bar-tag">MusicDSL & Computational Design</span>
                        </div>
                    </div>
                </div>

                <!-- Track 3: 逻辑推理与解释性 -->
                <div class="track-row">
                    <!-- VEX: 2022.10 - 2023.12 -->
                    <div class="exp-bar" style="left: 18.7%; width: 29.2%;">
                        <div class="bar-content">
                            <span class="bar-title">VEX Robotics Team Leader</span>
                            <span class="bar-tag">Tjulib Library & Odometry Positioning</span>
                        </div>
                    </div>
                    <!-- AI Safety Hungary: 2024.02 - 2024.04 -->
                    <div class="exp-bar" style="left: 52%; width: 4.2%;">
                        <div class="bar-content">
                            <span class="bar-title">AI Safety Hungary</span>
                            <span class="bar-tag">Alignment Trainee</span>
                        </div>
                    </div>
                    <!-- ByteDance: 2025.05 - 2025.10 -->
                    <div class="exp-bar" style="left: 81.2%; width: 12.5%;">
                        <div class="bar-content">
                            <span class="bar-title">ByteDance Intern</span>
                            <span class="bar-tag">Formal Reasoning (Lean 4) & Mech Interp</span>
                        </div>
                    </div>
                </div>

                <!-- Track 4: 工业界大规模训练 -->
                <div class="track-row">
                     <!-- Stepfun: 2025.12 开始，持续至今 -->
                     <div class="exp-bar ongoing auto-width current-task" data-start-year="2025" data-start-month="12">
                        <div class="bar-content">
                            <span class="bar-title">Stepfun</span>
                            <span class="bar-tag">LLM Pretrain</span>
                        </div>
                    </div>
                </div>

            </div> <!-- End tracks -->
        </div> <!-- End canvas -->
    </div> <!-- End viewer -->
    <p class="scroll-hint">← Drag to scroll | Updates automatically based on current date →</p>
</section>

<!-- ====================== RESEARCH & EXPERIENCE ======================= -->
<h2>Research Experience</h2>

<div class="exp-grid">


    <!-- Stepfun -->
    <div class="exp-row">
        <div class="exp-text">
            <div class="exp-title">Stepfun — LLM Pretrain Intern
                <a href="https://platform.stepfun.com/" target="_blank" class="pub-btn" style="margin-left:10px" >Link</a>
            </div>
            <div class="exp-time">Dec 2025 – Present</div>
            <p>
                Working on pretraining algorithms for large-scale models, focusing on optimization, data pipeline design, and scaling model training for enhanced performance and efficiency.
            </p>
        </div>
    </div>
    <!-- ByteDance -->
    <div class="exp-row">
        <div class="exp-text">
            <div class="exp-title">
                ByteDance — LLM Research Intern
                <a href="https://seed.bytedance.com/en/" target="_blank" class="pub-btn" style="margin-left:10px">Link</a>
            </div>
            <div class="advisor-block">
                <span class="advisor-prefix">Advised by </span>
                <a href="https://scholar.google.com/citations?user=OdE3MsQAAAAJ&hl=en" target="_blank" class="advisor-badge">Dr. Wenhao Huang</a>
                <a href="https://scholar.google.com/citations?user=qyTrq4kAAAAJ&hl=en" target="_blank" class="advisor-badge">Dr. Ge Zhang</a>
            </div>
            <div class="exp-time">May 2025 – Oct 2025</div>
            <p>
                Worked on formal reasoning and automated theorem proving with large language models (LLMs), constructing large datasets for reasoning experiments and evaluation.
            </p>
        </div>
    </div>

    <!-- MIT CSAIL -->
    <div class="exp-row">
        <div class="exp-text">
            <div class="exp-title">
                MIT CSAIL CDFG — Research Intern
                <a href="https://cdfg.csail.mit.edu/team" target="_blank" class="pub-btn" style="margin-left:10px">Link</a>
            </div>
            <div class="advisor-block">
                <span>Advised by </span>
                <a href="https://scholar.google.com/citations?hl=en&user=wbIMbL8AAAAJ" target="_blank" class="advisor-badge">
                    Prof. Wojciech Matusik
                </a>
                <span class="advisor-remote">(Remote)</span>
            </div>            
            <div class="exp-time">Jun 2025 – Present</div>
            <p>
                Developed MusicDSL, a domain-specific language for musical structure, and built middleware connecting DAWs with AI models.
            </p>
        </div>
    </div>

    <!-- MAP Lab -->
    <div class="exp-row">
        <div class="exp-text">
            <div class="exp-title">
                MAP Open Source Community — Intern
                <a href="https://huggingface.co/m-a-p" target="_blank" class="pub-btn" style="margin-left:10px">Link</a>
            </div>

            <div class="advisor-block">
                <span class="advisor-prefix">Advised by </span>
                <a href="https://scholar.google.com/citations?user=qyTrq4kAAAAJ&hl=en" target="_blank" class="advisor-badge">Dr. Ge Zhang</a>
                <span>& other community mentors</span>
            </div>

            <div class="exp-time">Oct 2023 – Present</div>
            <p>
                Focused on designing benchmarks and evaluation tools to systematically assess model reasoning capabilities, and authored detailed research reports supporting team projects and analyses.
            </p>
        </div>
    </div>

    <!-- Shanghai Institute for Intelligent Autonomous Systems -->
    <div class="exp-row">
        <div class="exp-text">
            <div class="exp-title">Shanghai Institute for Intelligent Autonomous Systems — Research Assistant
                <a href="https://srias.tongji.edu.cn/" target="_blank" class="pub-btn" style="margin-left:10px" >Link</a>
            </div>
            <div class="exp-time">Jun 2022 – Sep 2023</div>
            <p>
                Developed cloud–edge pedestrian re-identification algorithms, implemented multi-level clustering methods, and authored patents.
            </p>
        </div>
    </div>

    <!-- SPAR Project -->
    <div class="exp-row">
        <div class="exp-text">
            <div class="exp-title">SPAR Project — Mentee
                <a href="https://sparai.org/" target="_blank" class="pub-btn" style="margin-left:10px" >Link</a>
            </div>
            <div class="exp-time">Feb 2024 – Jun 2024</div>
            <p>
                Implemented a secure steganography system integrating iMEC and GPT-2.
            </p>
        </div>
    </div>
    

    <!-- AI Safety Hungary Technical Course -->
    <div class="exp-row">
        <div class="exp-text">
            <div class="exp-title">AI Safety Hungary Course — Trainee
                <a href="https://www.aishungary.com/" target="_blank" class="pub-btn" style="margin-left:10px">Link</a>
            </div>
            <div class="exp-time">Feb 2024 – Apr 2024</div>
            <p>Studied AI alignment and safety through technical readings and group discussions.</p>
        </div>
    </div>

</div>

<h2>Other Experience</h2>

<div class="other-exp-grid">
    <div class="other-exp-card">
        <div class="other-exp-header">
            <div>
                <div class="other-exp-title">
                    VEX Robotics Laboratory, Tongji University — Program Team Leader
                </div>
                <div class="other-exp-time">
                    Oct 2022 – Dec 2023
                </div>
            </div>
            <div class="other-exp-links">
                <a href="https://github.com/TongJiVex" target="_blank">Lab GitHub</a>
                <a href="https://github.com/TongJiVexProgramGroup" target="_blank">Program GitHub</a>
                <a href="https://www.bilibili.com/video/BV11q421w7JQ/?spm_id_from=333.1387.homepage.video_card.click&vd_source=35a8366f91f3ef012a5bcf44aaefceca" target="_blank">Videos</a>
                <a href="https://tongjivex.github.io/2022-2023_TJU_Engineering_Notebook/" target="_blank">Engineering Notes</a>
            </div>
        </div>
        <ul>Led the development of the <b>tjulib</b> library, overseeing design and coding of its functionality.
        and implemented an omni-directional octagonal chassis design and odometry algorithm for full-field positioning.
        </ul>
    </div>
</div>

<!-- ====================== PUBLICATIONS ======================= -->
<h2>Publications</h2>
<p style="font-size:0.9em; color: #555;">
    Listed in reverse chronological order (most recent first)
</p>
<div class="pub-grid">

    <div class="pub-card">
        <div class="pub-title">Scaling Latent Reasoning via Looped Language Models</div>
        <div class="pub-venue">Mechanistic Interpretability</div>
        <div class="pub-links">
            <a href="http://ouro-llm.github.io/" target="_blank" class="pub-btn">Website</a>
            <a href="https://arxiv.org/pdf/2510.25741" target="_blank" class="pub-btn">PDF</a>
        </div>
    </div>


    <div class="pub-card first-author">
        <div class="pub-title">Criticlean: Critic-guided reinforcement learning for mathematical formalization</div>
        <div class="pub-venue">Co-First Author</div>
        <div class="pub-links">
            <a href="https://github.com/multimodal-art-projection/CriticLean" target="_blank" class="pub-btn">Website</a>
            <a href="https://arxiv.org/pdf/2507.06181" target="_blank" class="pub-btn">PDF</a>
        </div>
    </div>

    <div class="pub-card">
        <div class="pub-title">Seed-Prover: Deep and broad reasoning for automated theorem proving</div>
        <div class="pub-venue">Data Support</div>
        <div class="pub-links">
            <a href="https://github.com/ByteDance-Seed/Seed-Prover" target="_blank" class="pub-btn">Website</a>
            <a href="https://arxiv.org/pdf/2507.23726" target="_blank" class="pub-btn">PDF</a>
        </div>
    </div>

    <div class="pub-card">
        <div class="pub-title">KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation</div>
        <div class="pub-venue">NeurIPS 2025 Spotlight • Game Support</div>
        <div class="pub-links">
            <a href="https://github.com/multimodal-art-projection/KORGym" target="_blank" class="pub-btn">Website</a>
            <a href="https://arxiv.org/pdf/2505.14552" target="_blank" class="pub-btn">PDF</a>
        </div>
    </div>

    <div class="pub-card first-author">
        <div class="pub-title">SuperGPQA: Scaling LLM Evaluation across 285 Graduate Disciplines</div>
        <div class="pub-venue">NeurIPS 2025 • Leading Author</div>
        <div class="pub-links">
            <a href="https://supergpqa.github.io/" target="_blank" class="pub-btn">Website</a>
            <a href="https://arxiv.org/pdf/2502.14739" target="_blank" class="pub-btn">PDF</a>
        </div>
    </div>

    <div class="pub-card first-author">
        <div class="pub-title">KOR-Bench: Benchmarking Language Models on Knowledge-Orthogonal Reasoning Tasks</div>
        <div class="pub-venue">ICLR 2025 • First Author</div>
        <div class="pub-links">
            <a href="https://kor-bench.github.io/" target="_blank" class="pub-btn">Website</a>
            <a href="https://arxiv.org/pdf/2410.06526" target="_blank" class="pub-btn">PDF</a>
        </div>
    </div>

    <div class="pub-card">
        <div class="pub-title">KARPA: A Training-free Method of Adapting Knowledge Graph as References for LLM’s Reasoning Path Aggregation</div>
        <div class="pub-venue">ACL Findings 2025 • Second Author</div>
        <div class="pub-links">
            <a href="https://github.com/Icamd/KARPA" target="_blank" class="pub-btn">Website</a>
            <a href="https://aclanthology.org/2025.findings-acl.1269.pdf" target="_blank" class="pub-btn">PDF</a>
        </div>
    </div>

    <div class="pub-card first-author">
        <div class="pub-title">CodeEditorBench: Evaluating Code Editing Capability of Large Language Models</div>
        <div class="pub-venue">ICLR 2025 DL4C • Co-First Author</div>
        <div class="pub-links">
            <a href="https://codeeditorbench.github.io/" target="_blank" class="pub-btn">Website</a>
            <a href="https://arxiv.org/pdf/2404.03543" target="_blank" class="pub-btn">PDF</a>
        </div>
    </div>

    <div class="pub-card">
        <div class="pub-title">SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval</div>
        <div class="pub-venue">Data Support</div>
        <div class="pub-links">
            <a href="https://github.com/Wusiwei0410/SciMMIR" target="_blank" class="pub-btn">Website</a>
            <a href="https://aclanthology.org/2024.findings-acl.746.pdf" target="_blank" class="pub-btn">PDF</a>
        </div>
    </div>

    <div class="pub-card">
        <div class="pub-title">MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series</div>
        <div class="pub-venue">Data Pipeline</div>
        <div class="pub-links">
            <a href="https://map-neo.github.io/" target="_blank" class="pub-btn">Website</a>
            <a href="https://arxiv.org/pdf/2405.19327" target="_blank" class="pub-btn">PDF</a>
        </div>
    </div>

</div>



<h2>Ongoing Long-term Project</h2>

<div class="exp-row">
    <div class="exp-text">
        <div class="exp-title">
            OpSynth-MI — Operator Synthesis for Mechanistic Interpretability
            <a href="https://github.com/opulse-exp/op_plus" target="_blank" class="pub-btn"  style="margin-left:16px;">GitHub</a>
        </div>
        <div class="exp-time">2025 – Present</div>
        <p>
            <b>OpSynth-MI is a long-term, lead-by-me research agenda</b> aimed at developing a systematic operator-based framework for mechanistic interpretability.
            Using newly defined operators, the project constructs a controllable <b>reasoning sandbox</b> that continuously simulates declarative and procedural knowledge from cognitive psychology, explicitly modeling dependencies between different knowledge types and exploring their compositional interactions. 
            This series of works seeks to progressively uncover and formalize the internal mechanisms of large language models, enhancing transparency and reasoning understanding.
        </p>
    </div>
</div>


<!-- ====================== RESEARCH VISION & CONCEPT MAPS ======================= -->
<h2>Research Vision & Concept Maps</h2>
<p style="font-size:0.9em; color:#555;">
    A collection of selected visual summaries of my research ideas, conceptual frameworks, and long-term directions.
</p>

<div class="research-carousel">
    <div class="slides">
        <div class="slide">
            <img src="./assets/overview_01.png" alt="Reasoning Roadmap" class="slide-img" onclick="openLightbox(this)">
            <div class="caption">Figure 1: Toward Deeper, Longer, and More Reliable Reasoning: Theory, Mechanisms, and Training Paradigms</div>
            <div class="description">
                This roadmap proposes a systematic framework for advancing AI reasoning via reproducible and interpretable patterns. A methodological loop—“theory → mechanism → training → feedback”—integrates abstract reasoning, mechanism analysis, and training design. Experimentally, a complementary cycle of clean and chaotic data tests capabilities, guides architecture, and drives iterative improvement. Together, these cycles enhance model reasoning in a controlled, interpretable, and reproducible manner, shifting research from engineering-driven practice toward foundational science.
            </div>
        </div>

        <!-- Slide 2 -->
        <div class="slide">
            <img src="./assets/overview_02.png" alt="Research Framework" class="slide-img" onclick="openLightbox(this)">
            <div class="caption">Figure 2: Wiser Agent, Wider World: Customizing the World for Agent Growth</div>
            <div class="description">
                This framework illustrates tiered agent training guided by WorldGPT, where synthetic environments are progressively adapted to the agent's skill level. A scheduler sets objectives, generates multimodal data, and iteratively refines both agent behavior and environment complexity, enabling continuous capability enhancement through feedback loops.
            </div>
        </div>

        <div class="slide">
            <img src="./assets/overview_03.png" alt="LLM-Empowered Embodied Intelligence" class="slide-img" onclick="openLightbox(this)">
            <div class="caption">Figure 3: LLM-Empowered Embodied Intelligence for Physical Interaction</div>
            <div class="description">
                This study addresses the semantic gap between physical multimodal data and LLM reasoning in embodied intelligence. We propose a framework that converts sensor data into LLM-interpretable formats, integrates physical rules, and constructs a task-specific reasoning library for single and multi-agent scenarios. A feedback-based mechanism iteratively refines LLM reasoning using execution outcomes, aiming to improve task success rates in complex, dynamic environments.
            </div>
        </div>
    </div>

    <div class="dots-container">
        <span class="dot active"></span>
        <span class="dot"></span>
        <span class="dot"></span>
    </div>
</div>

<!-- Lightbox Overlay -->
<div id="lightbox" onclick="closeLightbox()">
    <img id="lightbox-img" src="">
</div>

<script>
const slides = document.querySelectorAll('.slide');
const dots = document.querySelectorAll('.dot');
let current = 0;

function showSlide(index) {
    slides.forEach((s, i) => s.style.display = i === index ? 'flex' : 'none');
    dots.forEach((d, i) => d.classList.toggle('active', i === index));
    current = index;
}

dots.forEach((dot, i) => {
    dot.addEventListener('click', () => showSlide(i));
});

// 初始化显示第一张
showSlide(0);

function openLightbox(img) {
    document.getElementById('lightbox-img').src = img.src;
    document.getElementById('lightbox').style.display = 'flex';
}

function closeLightbox() {
    document.getElementById('lightbox').style.display = 'none';
}

</script>
<!-- ====================== AWARDS ======================= -->
<h2>Competition Awards</h2>

<div class="info-card">
    <p>
        <b>Excellence Award</b> — 2023 CCF Software Conference Robotics Large Model and Embodied Intelligence Competition
        <a href="https://chinasoft.ccf.org.cn/2023/notice/Robot.html" target="_blank" class="pub-btn" style="margin-left:10px">Link</a>
    </p>
    <p><b>First Prize</b> — Professional Track 1, 2023 AI for Brain Science Collegiate Challenge</p>
    <p><b>First Prize</b> — Creative Group, 2023 Shanghai Female Student Innovation and Entrepreneurship Competition</p>
    <p>
        <b>4th Place</b> — 2023 VEX Robotics World Championships VEX U Design Division
        <a href="https://recf.org/vex-robotics-world-championship/" target="_blank" class="pub-btn" style="margin-left:10px">Link</a>
    </p>
    <p><b>Design Award</b> — 2023 China University Students Intelligent Robot Creativity Competition</p>
</div>


<!-- ====================== SKILLS ======================= -->
<h2>Languages & Skills</h2>

<div class="info-card">
    <p><b>Languages:</b> Chinese (Native) | English (Fluent)</p>
    <p><b>Programming:</b> Python, C/C++, Verilog, JavaScript, HTML/CSS, Assembly</p>
    <p><b>Machine Learning & Deep Learning:</b> PyTorch, TensorFlow, HuggingFace Transformers</p>
    <p><b>Large Language Models:</b> Megatron-LM, vLLM, LLaMA-Factory (SFT), VERL (RL), NNSight (Interpretability), Ray (Distributed)</p>
    <p><b>Robotics & Simulation:</b> Mechanical Assembly, SolidWorks, 3D Printing, ROS, Sensors, Basic Control</p>
</div>


<footer>
    © 2025 Kaijing Ma
</footer>

</body>
</html>
